{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems relevant: https://gist.github.com/arunaugustine/5551446"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aifc\n",
    "import numpy as np\n",
    "import h5py\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine distribution of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fft_data_file = h5py.File(\"all_whale_training_fft_30000samples_shape2001x2.hdf5\", 'r')\n",
    "all_timeseries_data_file = h5py.File(\"all_whale_training_30000samples_shape4000.hdf5\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fft_data_file['labels'], np.array(all_fft_data_file['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to randomly reorder the data before splitting.\n",
    "This is to ensure that each split has about the same ratio of signal/no signal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fft_data_file.keys(), all_timeseries_data_file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are all the labels in the same order? \n",
    "(np.array(all_fft_data_file['labels']) == np.array(all_timeseries_data_file['labels'])).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, so we can combine these \n",
    "timeseries_fft_labels = []\n",
    "for i in range(len(all_fft_data_file['labels'])):\n",
    "    timeseries_fft_labels.append([\n",
    "        all_timeseries_data_file['data'][i],\n",
    "        all_fft_data_file['data'][i],\n",
    "        all_timeseries_data_file['labels'][i]\n",
    "    ])\n",
    "timeseries_fft_labels = np.array(timeseries_fft_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_fft_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_labels = []\n",
    "for i in range(len(timeseries_fft_labels.T[2])):\n",
    "    if timeseries_fft_labels.T[2][i][0] == 1:\n",
    "        flat_labels.append(1)\n",
    "    else:\n",
    "        flat_labels.append(0)\n",
    "plt.figure()\n",
    "plt.plot(flat_labels, linewidth=0.05)\n",
    "plt.title('Label distribution before shuffle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(timeseries_fft_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_labels = []\n",
    "for i in range(len(timeseries_fft_labels.T[2])):\n",
    "    if timeseries_fft_labels.T[2][i][0] == 1:\n",
    "        flat_labels.append(1)\n",
    "    else:\n",
    "        flat_labels.append(0)\n",
    "plt.figure()\n",
    "plt.plot(flat_labels, linewidth=0.05)\n",
    "plt.title('Label distribution after shuffle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very good! It's much more evenly distributed now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training/validation/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indicies = int(0.2 * 30000)\n",
    "train_indicies = test_indicies + int(0.8 * (0.8 * 30000))\n",
    "validataion_indicies = train_indicies + int(0.8 * (0.2 * 30000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indicies, train_indicies, validataion_indicies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up the timeseries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "test_data = []\n",
    "test_labels = []\n",
    "for i in range(test_indicies):\n",
    "    test_data.append(timeseries_fft_labels[i][0])\n",
    "    test_labels.append(timeseries_fft_labels[i][2])\n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Training data \n",
    "training_data = []\n",
    "training_labels = []\n",
    "for i in range(test_indicies, train_indicies):\n",
    "    training_data.append(timeseries_fft_labels[i][0])\n",
    "    training_labels.append(timeseries_fft_labels[i][2])\n",
    "training_data = np.array(training_data)\n",
    "training_labels = np.array(training_labels)\n",
    "\n",
    "# Validation data \n",
    "validation_data = []\n",
    "validation_labels = []\n",
    "for i in range(train_indicies, validataion_indicies):\n",
    "    validation_data.append(timeseries_fft_labels[i][0])\n",
    "    validation_labels.append(timeseries_fft_labels[i][2])\n",
    "validation_data = np.array(validation_data)\n",
    "validation_labels = np.array(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape, training_data.shape, validation_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_data[0][9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the split data\n",
    "\n",
    "split_data_file = h5py.File(\n",
    "    \"whale_training_timeseries_samples19200train4800val6000test_shape4000_gen20171129.hdf5\", 'w-')\n",
    "\n",
    "split_data_file.create_dataset(\"training_data\", dtype=np.short, shape=training_data.shape)\n",
    "split_data_file['training_data'][...] = training_data\n",
    "\n",
    "split_data_file.create_dataset(\"training_labels\", dtype='i', shape=training_labels.shape)\n",
    "split_data_file['training_labels'][...] = training_labels\n",
    "\n",
    "split_data_file.create_dataset(\"validation_data\", dtype=np.short, shape=validation_data.shape)\n",
    "split_data_file['validation_data'][...] = validation_data\n",
    "\n",
    "split_data_file.create_dataset(\"validation_labels\", dtype='i', shape=validation_labels.shape)\n",
    "split_data_file['validation_labels'][...] = validation_labels\n",
    "\n",
    "split_data_file.create_dataset(\"testing_data\", dtype=np.short, shape=test_data.shape)\n",
    "split_data_file['testing_data'][...] = test_data\n",
    "\n",
    "split_data_file.create_dataset(\"testing_labels\", dtype='i', shape=test_labels.shape)\n",
    "split_data_file['testing_labels'][...] = test_labels\n",
    "\n",
    "split_data_file.flush()\n",
    "split_data_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up the fft data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "fft_test_data = []\n",
    "fft_test_labels = []\n",
    "for i in range(test_indicies):\n",
    "    fft_test_data.append(timeseries_fft_labels[i][1])\n",
    "    fft_test_labels.append(timeseries_fft_labels[i][2])\n",
    "fft_test_data = np.array(fft_test_data)\n",
    "fft_test_labels = np.array(fft_test_labels)\n",
    "\n",
    "# Training data \n",
    "fft_training_data = []\n",
    "fft_training_labels = []\n",
    "for i in range(test_indicies, train_indicies):\n",
    "    fft_training_data.append(timeseries_fft_labels[i][1])\n",
    "    fft_training_labels.append(timeseries_fft_labels[i][2])\n",
    "fft_training_data = np.array(fft_training_data)\n",
    "fft_training_labels = np.array(fft_training_labels)\n",
    "\n",
    "# Validation data \n",
    "fft_validation_data = []\n",
    "fft_validation_labels = []\n",
    "for i in range(train_indicies, validataion_indicies):\n",
    "    fft_validation_data.append(timeseries_fft_labels[i][1])\n",
    "    fft_validation_labels.append(timeseries_fft_labels[i][2])\n",
    "fft_validation_data = np.array(fft_validation_data)\n",
    "fft_validation_labels = np.array(fft_validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_test_data.shape, fft_training_data.shape, fft_validation_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fft_test_data[0][9][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the split data\n",
    "\n",
    "split_fft_data_file = h5py.File(\n",
    "    \"whale_training_fft_samples19200train4800val6000test_shape2001x2_gen20171129.hdf5\", 'w-')\n",
    "\n",
    "split_fft_data_file.create_dataset(\"training_data\", dtype=np.short, shape=fft_training_data.shape)\n",
    "split_fft_data_file['training_data'][...] = fft_training_data\n",
    "\n",
    "split_fft_data_file.create_dataset(\"training_labels\", dtype='i', shape=fft_training_labels.shape)\n",
    "split_fft_data_file['training_labels'][...] = fft_training_labels\n",
    "\n",
    "split_fft_data_file.create_dataset(\"validation_data\", dtype=np.short, shape=fft_validation_data.shape)\n",
    "split_fft_data_file['validation_data'][...] = fft_validation_data\n",
    "\n",
    "split_fft_data_file.create_dataset(\"validation_labels\", dtype='i', shape=fft_validation_labels.shape)\n",
    "split_fft_data_file['validation_labels'][...] = fft_validation_labels\n",
    "\n",
    "split_fft_data_file.create_dataset(\"testing_data\", dtype=np.short, shape=fft_test_data.shape)\n",
    "split_fft_data_file['testing_data'][...] = fft_test_data\n",
    "\n",
    "split_fft_data_file.create_dataset(\"testing_labels\", dtype='i', shape=fft_test_labels.shape)\n",
    "split_fft_data_file['testing_labels'][...] = fft_test_labels\n",
    "\n",
    "split_fft_data_file.flush()\n",
    "split_fft_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
